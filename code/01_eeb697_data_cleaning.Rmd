---
title: "Untitled"
author: "Kirsten Fuller"
date: "1/19/2022"
output:
  word_document: default
  html_document: default
---
For my term project I will be exploring brown pelican movement data to answer the question: Are there individual differences in time spent over land vs. time spent over water for brown pelicans in the Gulf of Mexico?

## Set Working Directory
```{r setup, include=FALSE}
rm( list = ls() ); gc( )

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/Boise_State/classes/eeb697_movement_ecol")
```

## Prepare Workspace
```{r, include = FALSE, message = FALSE}
# load necessary packages
# define packages
packages <- c("tidyverse", "dplyr", "tidyr", "gtools", "ggplot2", "lubridate", "reshape2", "plyr", "rgdal", "sp", "sf", "maptools", "raster", "amt", "FedData", "tiff", "terra")

# install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# load packages
invisible(lapply(packages, library, character.only = TRUE))
```

Data was acquired from various sources for this analysis. The brown pelican data was publicly available on Movebank.org (Geary B, Walter ST, Leberg PL, Karubian J (2018) Condition-dependent foraging strategies in a coastal seabird: evidence for the rich get richer hypothesis. Behavioral Ecology. doi:10.1093/beheco/ary173). 

## Load Data
```{r, message = FALSE}
# pelican location data
pel_dat <- read.csv("data/brown_pelican_data.csv")

# pelican reference data
pel_dat_ref_dat <- read.csv("data/brown_pelican_reference_data.csv")

# load in the landcover data for the gulf of mexico
gom_shp <- st_read("data/gulf_shp/gulf-of-mexico-protraction-polygons.shp")

# load marine species diversity data
spec_div <- terra::rast("data/global_marine_fish.tif")
```

Cleaning the data included exploring the data, removing unnecessary columns, defining the timestamps in the proper format and time zone, and joining tabular data together to make a data base for analysis.

## General Data Cleaning
```{r}
# PRIMARY DATA:
# check column names of pelican data
colnames(pel_dat)

# remove unnecessary columns and change col names to be more succinct
pel_dat_sub <- pel_dat %>%
# get rid of unnecessary columns
  dplyr::select(-c(visible, study.name, tag.local.identifier, sensor.type, individual.taxon.canonical.name))%>% 
# rename columns
  dplyr::rename(animal.id = individual.local.identifier,
                long = location.long,
                lat = location.lat)

# create time stamp column, year, month, and date columns
pel_dat_sub <- pel_dat_sub %>%
  dplyr::mutate(timestamp = lubridate::ymd_hms(pel_dat$timestamp, tz = "EST"))

pel_dat_sub <- pel_dat_sub %>%
  dplyr::mutate(year = as.numeric(format(pel_dat_sub$timestamp, format = "%Y")),
                month = as.numeric(format(pel_dat_sub$timestamp, format = "%m")),
                day = as.numeric(format(pel_dat_sub$timestamp, format = "%d")),
                week = lubridate::week(pel_dat_sub$timestamp),
                ID = row_number()) %>%
  dplyr::select(-event.id)

# create a table to tally up data by year
count((pel_dat_sub$year)) # 2014 had the most data @ 18,861 points

# subset out just that year
pel_dat_14 <- pel_dat_sub %>%
  dplyr::filter(year == "2014")

# determine the number of individals included in the study in 2014
length(unique(pel_dat_14$animal.id)) # 13 individuals

# determine which week has the most animals
table(pel_dat_14$week, by = pel_dat_14$animal.id) # okay so 26, 27 and 28 look bad
# 20 and 21 look the best, with all 13 animals having data
# I'm going to pick 20

pel_dat_14_wk20 <- pel_dat_14 %>%
  dplyr::filter(week == "20")
```

I assessed the amount of data I had and over what time frame. 2014 had the most data at 18,861 points, so I filtered the data to that year. I then looked at the number of individuals in 2014 (there were 13 included in the study that year), and assessed which week of the study in 2014 included the most individuals. Weeks 20 and 21 looked about the same with 13 individuals included in both of them. Week 20 was ultimately selected for having slightly more data.

```{r}
# pelican reference data:
colnames(pel_dat_ref_dat)

# select only the columns of interest
pel_dat_ref_dat_sub <- pel_dat_ref_dat %>%
  dplyr::select(animal.id, animal.sex)

# How many males and females are included in the study?
count(pel_dat_ref_dat_sub$animal.sex) # 14 females and 16 males

# join the reference data to the week 20 data
pel_dat_join <- left_join(pel_dat_14_wk20, pel_dat_ref_dat_sub, by = "animal.id") 
```

Next came the spatial defining of the data. 

## Spatial Defining
```{r}
# check if it has a defined coordinate system
st_crs(pel_dat_join_sub) # currently NA, but I know it should be WGS84 from the reference txt
st_crs(gom_shp) # NAD27
st_crs(spec_div) # World_Eckert_IV 

# define the coordinate reference system of the pelican data
# the READ_ME file says the pelican data is WGS84, so I will have to define the crs as an object.The EPSG code for that is 4326
pel_crs = "EPSG:4326"

# then assign the pelican data to that crs
pel_dat_sf <- sf::st_as_sf(pel_dat_join_sub, coords = c("long", "lat"),
                           crs = st_crs(pel_crs))


# Gulf of Mexico land/gulf boundary:
# the goal here is to 
  # 1. spatially align the gulf shp with the pelican data
  # 2. spatially join them and use mutate to make a column that assigns the data to either within gulf of not (NA)

# match the crs of the gulf of mexico shapefile to the crs of the pelican data
gom_shp_trans <- st_transform(gom_shp, crs = st_crs(pel_crs)) %>%
  dplyr::select(PROT_NAME, geometry) # select only the columns of interest

# make sure the crs of the pelican data and the gulf of mexico data match
st_crs(pel_dat_sf) == st_crs(gom_shp_trans)

# crop the gulf shape file to the extent of the pelican data
gom_shp_trans_crop <- st_crop(gom_shp_trans, st_bbox(pel_dat_sf)) # note this is just for plotting purposes

# spatial join
pel_dat_sf <- st_join(pel_dat_sf, gom_shp_trans, left = TRUE)

# replace NA values in the PROT_NAME column with land and replace values that aren't na with gulf
pel_dat_sf$PROT_NAME <- ifelse(is.na(pel_dat_sf$PROT_NAME) == TRUE, "land", "gulf")

# rename the PROT_NAME column to land_type
pel_dat_sf <- pel_dat_sf %>%
  dplyr::rename(land_type = PROT_NAME)


# species raster:
# the goal here is to extract predictor data from the raster at the spatial points in the pelican dataframe. When possible, it is better to convert sf data to the crs of a raster, rather than transforming a raster to match the crs of a sf object. Here is the plan for that.
  # 1. convert pelican data to crs of raster
  # 2. extract predictor data from raster
  # 3. convert pelican data back to original crs (pel_crs)

# define the crs of the raster into an object
rast_crs <- st_crs(spec_div) 

# transform pelican data to species diversity raster
pel_dat_sf_trans <- pel_dat_sf %>%
  st_transform(pel_dat_sf, crs = rast_crs) 

# this asks, does pelican crs equal the species crs?
st_crs(pel_dat_sf_trans) == st_crs(spec_div) 

# check data classes. Species div is a spatRaster, pelican data is in sf
class(spec_div); class(pel_dat_sf_trans) 

# convert pelican data to a spat vector
pel_spatvect <- vect(pel_dat_sf_trans); class(pel_spatvect) 

# extract data from raster
rast_data_vect <- terra::extract(spec_div, pel_spatvect, drop = FALSE) 

# join that data vector back to the original pelican data
pel_dat_sf <- left_join(pel_dat_sf, rast_data_vect)
```


## Defining Tracks and Exploring Data
```{r}
# define the tracks
pel_tracks <- amt::make_track(pel_dat_join_sub, .x = long, .y = lat, .t = timestamp,
                              animal.id, day, animal.sex,
                              crs = 4326)

# turn data into to an sf object for ggplotting purposes
pel_tracks_sf <- as_sf_points(pel_tracks)

# plot all of the tracks together on top of the gulf shapefile
ggplot() +   
  geom_sf(data = gom_shp_trans_crop, inherit.aes = FALSE ) +
  geom_sf(data = pel_tracks_sf, aes(col = as.factor(animal.id))) +
  theme(legend.position="none")

# summarize the data
amt::summarize_sampling_rate(pel_tracks)

# turn into a tibble list by grouping and nesting by individual animals:
pel_tracks_nested <- pel_tracks %>%  amt::nest(data = -"animal.id")

# plot each individual's track
for( i in 1:dim(pel_tracks_nested)[1]){
  a <- as_sf_points(pel_tracks_nested$data[[i]] ) %>% 
    ggplot(.) + theme_bw(base_size = 12) +
    labs( title = paste0('individual =', pel_tracks_nested$animal.id[i]) ) +
    geom_sf(data = gom_shp_trans_crop, inherit.aes = FALSE ) +
    geom_sf() 
  print(a)
} 

# calculate step lengths
pel_tracks_test <- pel_tracks %>%
  dplyr::mutate(sl = step_lengths(.)) %>%
  dplyr::mutate(direction_p = direction_rel(.))

# plot step lengths
pel_tracks_test %>% 
  select(animal.id, sl) %>% 
  ggplot(aes(sl, fill = factor(animal.id))) + 
  geom_density(alpha = 0.4)


# NOT FUNCTIONING YET, COME BACK TO THIS
# check autocorrelation in step length for each individual
# for( i in 1:dim(pel_tracks_test)[1] ){
  # extract individual ids
#  idd <- pel_tracks_test$animal.id[i]
  # use tibbles we calculated in steps
#  x <- pull(pel_tracks_test[["sl"]][[i]], direction_p)
  # remove missing data
#  x <- x[!is.na(x)]
  # calculate autocorrelation function:
#  acf( x, lag.max = 300,
 #      main = paste0( "individual = ", idd ) )
#}
```

## Save Relevant Objects
```{r}
#save workspace in case we need to make changes
save.image( "TracksWorkspace.RData" )
```

